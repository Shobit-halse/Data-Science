{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508ae975",
   "metadata": {},
   "source": [
    "# Sheth L.U.J. & Sir M.V. College Of Arts, Science & Commerce\n",
    "\n",
    "# 3B Practical Handling Categorial Data\n",
    "\n",
    "# Shobit Halse | T083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (75, 7)\n",
      "\n",
      "First few rows:\n",
      "   Unnamed: 0        Artist                  Title            Album    Year  \\\n",
      "0           0  Charlie Puth              Attention       Voicenotes  2017.0   \n",
      "1           1  Charlie Puth  We Donâ€™t Talk Anymore  Nine Track Mind  2016.0   \n",
      "2           2  Charlie Puth               How Long       Voicenotes  2017.0   \n",
      "3           3  Charlie Puth            Marvin Gaye  Nine Track Mind  2015.0   \n",
      "4           4  Charlie Puth          One Call Away  Nine Track Mind  2015.0   \n",
      "\n",
      "         Date                                              Lyric  \n",
      "0  2017-04-21  woahoh hmhmm   you've been runnin' 'round runn...  \n",
      "1  2016-05-24  charlie puth we don't talk anymore we don't ta...  \n",
      "2  2017-10-05  alright ooh yeah   i'll admit i was wrong what...  \n",
      "3  2015-02-10  charlie puth let's marvin gaye and get it on y...  \n",
      "4  2015-08-20  i'm only one call away i'll be there to save t...  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75 entries, 0 to 74\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  75 non-null     int64  \n",
      " 1   Artist      75 non-null     object \n",
      " 2   Title       75 non-null     object \n",
      " 3   Album       48 non-null     object \n",
      " 4   Year        58 non-null     float64\n",
      " 5   Date        58 non-null     object \n",
      " 6   Lyric       75 non-null     object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 4.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv('CharliePuth.csv')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoding-nominal",
   "metadata": {},
   "source": [
    "# Encoding Nominal Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "encoding-nominal-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature:\n",
      "[['Voicenotes']\n",
      " ['Nine Track Mind']\n",
      " ['Voicenotes']\n",
      " ['Nine Track Mind']\n",
      " ['Nine Track Mind']]\n",
      "\n",
      "One-hot encoded:\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Feature classes:\n",
      "['Nine Track Mind' 'Voicenotes']\n",
      "\n",
      "Reverse one-hot encoding:\n",
      "['Voicenotes' 'Nine Track Mind' 'Voicenotes' 'Nine Track Mind'\n",
      " 'Nine Track Mind']\n"
     ]
    }
   ],
   "source": [
    "feature = df[['Album']].values\n",
    "\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "print(one_hot.fit_transform(feature)[:5])\n",
    "\n",
    "print(one_hot.classes_[:5])\n",
    "\n",
    "print(one_hot.inverse_transform(one_hot.transform(feature))[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pandas-dummies",
   "metadata": {},
   "source": [
    "# Using Pandas get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pandas-dummies-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding with pandas:\n",
      "   Nine Track Mind  Voicenotes\n",
      "0            False        True\n",
      "1             True       False\n",
      "2            False        True\n",
      "3             True       False\n",
      "4             True       False\n"
     ]
    }
   ],
   "source": [
    "print(\"One-hot encoding with pandas:\")\n",
    "print(pd.get_dummies(df['Album'].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiclass",
   "metadata": {},
   "source": [
    "# Multiclass One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "multiclass-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass one-hot encoded:\n",
      "[[0 1 0 1]\n",
      " [1 0 1 0]\n",
      " [0 1 0 1]\n",
      " [1 1 0 0]\n",
      " [0 0 1 1]]\n",
      "\n",
      "Classes:\n",
      "['Nine Track Mind' 'Pop' 'R&B' 'Voicenotes']\n"
     ]
    }
   ],
   "source": [
    "multiclass_feature = list(zip(df['Album'], df['Year'].astype(str)))\n",
    "\n",
    "multiclass_feature = [(a, str(int(float(y)))) if pd.notna(y) else (a, 'Unknown') for a, y in multiclass_feature]\n",
    "\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "\n",
    "print(one_hot_multiclass.fit_transform(multiclass_feature)[:5])\n",
    "print(one_hot_multiclass.classes_[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoding-ordinal",
   "metadata": {},
   "source": [
    "# Encoding Ordinal Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "encoding-ordinal-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original scores:\n",
      "    Score\n",
      "0     Low\n",
      "1     Low\n",
      "2  Medium\n",
      "3  Medium\n",
      "4    High\n",
      "\n",
      "Mapped scores:\n",
      "0    1\n",
      "1    1\n",
      "2    2\n",
      "3    2\n",
      "4    3\n",
      "Name: Score, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_10872\\1391996188.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(score_df[\"Score\"].replace(scale_mapper))\n"
     ]
    }
   ],
   "source": [
    "score_df = pd.DataFrame({\"Score\": [\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})\n",
    "\n",
    "print(\"Original scores:\")\n",
    "print(score_df)\n",
    "\n",
    "scale_mapper = {\n",
    "    \"Low\": 1,\n",
    "    \"Medium\": 2,\n",
    "    \"High\": 3\n",
    "}\n",
    "\n",
    "print(\"\\nMapped scores:\")\n",
    "print(score_df[\"Score\"].replace(scale_mapper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dict-vectorizer",
   "metadata": {},
   "source": [
    "# Encoding Dictionaries of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dict-vectorizer-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary vectorized features:\n",
      "[[4. 2. 0.]\n",
      " [3. 4. 0.]\n",
      " [0. 1. 2.]\n",
      " [0. 2. 2.]]\n",
      "\n",
      "Feature names:\n",
      "['Blue' 'Red' 'Yellow']\n"
     ]
    }
   ],
   "source": [
    "data_dict = df[['Album', 'Year', 'Title']].to_dict(orient='records')\n",
    "\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "print(features[:5])\n",
    "\n",
    "print(dictvectorizer.get_feature_names_out()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imputing-knn",
   "metadata": [],
   "source": [
    "# Imputing Missing Class Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "imputing-knn-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed values using KNN:\n",
      "[[ 0.    0.87  1.31]\n",
      " [ 1.   -0.67 -0.22]\n",
      " [ 0.    2.1   1.45]\n",
      " [ 1.    1.18  1.33]\n",
      " [ 0.    1.22  1.27]\n",
      " [ 1.   -0.21 -1.19]]\n"
     ]
    }
   ],
   "source": [
    "X = df[['Year']].values\n",
    "y = df['Album'].values\n",
    "\n",
    "X_with_nan = np.array([\n",
    "    [df['Year'][0]],\n",
    "    [np.nan],\n",
    "    [df['Year'][2]]\n",
    "])\n",
    "\n",
    "y_with_nan = np.array([\n",
    "    y[0],\n",
    "    None,\n",
    "    y[2]\n",
    "])\n",
    "\n",
    "train_idx = [0, 2]\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "n_neighbors = max(1, min(3, len(X_train)))\n",
    "clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights='distance')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X)\n",
    "\n",
    "X_with_nan_imputed = imputer.transform(X_with_nan)\n",
    "\n",
    "imputed_values = clf.predict(X_with_nan_imputed[[1]])\n",
    "\n",
    "y_with_imputed = y_with_nan.copy()\n",
    "y_with_imputed[1] = imputed_values[0]\n",
    "\n",
    "X_with_imputed = X_with_nan_imputed\n",
    "\n",
    "print(\"Imputed numeric rows:\\n\", X_with_imputed)\n",
    "print(\"Imputed labels:\\n\", y_with_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imputing-frequent",
   "metadata": {},
   "source": [
    "# Fill Missing Values With Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imputing-frequent-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed with most frequent value:\n",
      "[[ 0.    0.87  1.31]\n",
      " [ 0.   -0.67 -0.22]\n",
      " [ 0.    2.1   1.45]\n",
      " [ 1.    1.18  1.33]\n",
      " [ 0.    1.22  1.27]\n",
      " [ 1.   -0.21 -1.19]]\n"
     ]
    }
   ],
   "source": [
    "X = df[['Album']].values\n",
    "\n",
    "imputer = SimpleImputer(missing_values=None, strategy='most_frequent')\n",
    "\n",
    "imputed_X = imputer.fit_transform(X)\n",
    "\n",
    "imputed_X[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imbalanced-classes",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "imbalanced-classes-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "[1 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "Class counts:\n",
      "0    62\n",
      "1    13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Random Forest with custom weights:\n",
      "RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})\n"
     ]
    }
   ],
   "source": [
    "df_binary = df.copy()\n",
    "df_binary['is_voicenotes'] = np.where(df_binary['Album'] == 'Voicenotes', 1, 0)\n",
    "\n",
    "target = df_binary['is_voicenotes'].values\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(target)\n",
    "print(\"\\nClass counts:\")\n",
    "print(pd.Series(target).value_counts())\n",
    "\n",
    "weights = {0: .9, 1: 0.1}\n",
    "\n",
    "clf = RandomForestClassifier(class_weight=weights)\n",
    "print(\"\\nRandom Forest with custom weights:\")\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-weights",
   "metadata": {},
   "source": [
    "# Using Balanced Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "balanced-weights-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with balanced weights:\n",
      "RandomForestClassifier(class_weight='balanced')\n"
     ]
    }
   ],
   "source": [
    "clf_balanced = RandomForestClassifier(class_weight=\"balanced\")\n",
    "print(\"Random Forest with balanced weights:\")\n",
    "print(clf_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downsampling",
   "metadata": {},
   "source": [
    "# Downsampling Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "downsampling-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 62\n",
      "Class 1 count: 13\n",
      "\n",
      "Downsampled target:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Downsampled class distribution:\n",
      "0    13\n",
      "1    13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "i_class0 = np.where(target == 0)[0]\n",
    "i_class1 = np.where(target == 1)[0]\n",
    "\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)\n",
    "\n",
    "print(f\"Class 0 count: {n_class0}\")\n",
    "print(f\"Class 1 count: {n_class1}\")\n",
    "\n",
    "if n_class1 > n_class0:\n",
    "    i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)\n",
    "    downsampled_target = np.hstack((target[i_class0], target[i_class1_downsampled]))\n",
    "else:\n",
    "    i_class0_downsampled = np.random.choice(i_class0, size=n_class1, replace=False)\n",
    "    downsampled_target = np.hstack((target[i_class0_downsampled], target[i_class1]))\n",
    "\n",
    "print(\"\\nDownsampled target:\")\n",
    "print(downsampled_target)\n",
    "print(\"\\nDownsampled class distribution:\")\n",
    "print(pd.Series(downsampled_target).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upsampling",
   "metadata": {},
   "source": [
    "# Upsampling Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "upsampling-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled target:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Upsampled class distribution:\n",
      "0    62\n",
      "1    62\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if n_class0 < n_class1:\n",
    "    i_class0_upsampled = np.random.choice(i_class0, size=n_class1, replace=True)\n",
    "    upsampled_target = np.concatenate((target[i_class0_upsampled], target[i_class1]))\n",
    "else:\n",
    "    i_class1_upsampled = np.random.choice(i_class1, size=n_class0, replace=True)\n",
    "    upsampled_target = np.concatenate((target[i_class0], target[i_class1_upsampled]))\n",
    "\n",
    "print(\"Upsampled target:\")\n",
    "print(upsampled_target)\n",
    "print(\"\\nUpsampled class distribution:\")\n",
    "print(pd.Series(upsampled_target).value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
